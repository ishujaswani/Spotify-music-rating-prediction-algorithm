# ğŸµ Spotify Music Rating Prediction Algorithm ğŸµ

![Spotify Music Analysis](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExaTQ2bDVrYmkydzNnYnZwZzBhdXZnczVrNGZzaGhzZTlpbWdrdnhmMCZlcD12MV9naWZzX3NlYXJjaCZjdD1n/EFGXDUBXcUd131C0CR/giphy.gif)

## ğŸš€ Overview
This repository contains the code and analysis for **Spotify's Predictive Analytics Competition** on Kaggle. The goal of this project is to **predict song ratings** using multiple parameters such as artist, genre, quality, and tempo of the music.

## ğŸ“Š Dataset
The dataset consists of various attributes of songs, including:
- ğŸ¼ **Genres** (One-hot encoded top 10 genres)
- ğŸšï¸ **Tempo**
- ğŸ”¥ **Quality**
- ğŸ¤ **Artist Information**
- â­ **Ratings (Target Variable)**

### ğŸ› ï¸ Data Preprocessing
âœ… Removed missing values (~1% of data)  
âœ… Expanded the **genres column** into individual categories  
âœ… Dropped non-informative columns (e.g., performers)  

## ğŸ“‰ Methodology
The project follows a structured **machine learning pipeline**:

1ï¸âƒ£ **Data Wrangling & Cleaning** ğŸ§¼  
   - Removed missing values  
   - One-hot encoded genres  
   - Dropped non-informative columns  

2ï¸âƒ£ **Data Visualization** ğŸ“Š  
   - Used `ggplot` and `ggcorplot` to visualize feature relationships  

3ï¸âƒ£ **Model Training & Evaluation** ğŸ¤–  
   - Applied **23 different regression models**  
   - Selected **Random Forest (Ranger Package)** as the best model with the lowest RMSE  
   - Hyperparameter tuning for **optimal performance**  

## ğŸ”¥ Model Performance

| ğŸ† Model                   | ğŸ¯ RMSE (Train) | ğŸ¯ RMSE (Test) |
|----------------------------|---------------|---------------|
| ğŸ“ Regression             | 15.2378       | 15.2145       |
| ğŸ¹ Lasso                  | 15.3012       | 15.2769       |
| ğŸŒ³ Decision Tree         | 15.7629       | 15.7159       |
| ğŸŒ² **Random Forest (Ranger)** | **6.68**  | **14.87**  |
| ğŸ› ï¸ Tuned RF (Pro Max)   | **10.79**  | **14.85**  |
| ğŸš€ XGBoost               | 13.80         | 15.09         |

ğŸ… **Best-performing model:** **Tuned Random Forest (Ranger)** with an RMSE of **14.85** on the test set.

## ğŸ”‘ Key Takeaways
ğŸ’¡ **Feature Engineering Matters**: Properly encoding categorical variables and selecting key features significantly improved model performance.  
ğŸ’¡ **Hyperparameter Tuning is Essential**: Adjusting parameters like the number of trees, `mtry`, and `min-node-size` **reduced RMSE**.  
ğŸ’¡ **Computational Limitations**: Some models took **hours** to run. Using **PCA or shrinkage models** could optimize computation.  

## ğŸ“ Files in the Repository
ğŸ“œ `PAC_ishu.Rmd` - R Markdown file with full analysis and implementation  
ğŸ“‚ `scoringData.csv` - Dataset used for predictions  
ğŸ“‘ `PAC.pdf` - Report documenting project methodology and results  
ğŸ“„ `Spotify PAC.pdf` - Summary document on the competition  
ğŸ“œ `LICENSE` - License for this project  
ğŸ“˜ `README.md` - Project documentation  

## ğŸ“œ License
This project is licensed under the **MIT License**. See `LICENSE` for more details.

## ğŸ‘¤ Author
**Ishu Jaswani**  
ğŸ“ **Masterâ€™s in Analytics, Columbia University**  

ğŸ“§ Contact: [ij2243@columbia.edu](mailto:ij2243@columbia.edu)  

---
